**这是一个用来记录ML，RLHF学习过程的仓库。**

```
ML
├── DPO
│   ├── DPO.html
│   ├── DPO.md
│   ├── train.py
│   ├── infer_DPO.py
│   └── dpo_train.py
└── README.md
```

1. `DPO.html/DPO.md`:关于DPO数学公式的推导
2. `train.py`:用于训练并使用Qwen2-0.5B模型
3. `dpo_train.py`:用于DPO训练
4. `infer_DPO.py`:用于使用Qwen2-0.5B经过trl数据集DPO训练后的模型

模型过于庞大存于本地